INTRODUCTION

Machine Learning methods have made remarkable impact in real world applications. A variety of these applications, including face recognition, machine translation, self-driving cars, search engines, autonomous robots, recommendation systems, computer games, etc., heavily rely on machine learning methods. Yet, theoretically, we do not have a good understanding of these methods.
Most of the problems that we come across in the field of Machine Learning is mainly non-convex. To understand the proper prediction and to have an accurate learning curve formulation we use optimization algorithms. Among these algorithms, the most widely used algorithm is Gradient Descent. But the Gradient Descent is best applied on a convex problem, but still, it does give a base for the formulation of advanced algorithms for different non-linear problems.
This paper attempts to discuss the complexities of a non-convex problem optimization in the field of Machine Learning. As in the real world, most of the scenarios don't fit in the convex problem representation. Most of the real-world problems are non-convex problems like face recognition, recommendation systems, autonomous robots and so on. In this is paper we will first attempt to understand the non-convex problem, Gradient Descent algorithm as an optimization algorithm and work towards understanding why it is hard to solve a non- convex problem and the possible problems to this NP-hard problem.
With the understanding of the non-convex problem optimization complexities with base Gradient Descent algorithm, other advanced algorithms are explored in order to have the best fit for the model function. This approach can then be applied to few real-world problems, from my organization, to formulate the model function that best fits the solution.
While Gradient Descent is a works best with a convex style problem, it may not be an ideal approach for a non-convex problem. Below graph represents a non-convex problem type.
Basically, in a non-convex problem statement there can be various local minima and single global minima or a flat region which makes it a little difficult to predict the global minimum point in the graph.
